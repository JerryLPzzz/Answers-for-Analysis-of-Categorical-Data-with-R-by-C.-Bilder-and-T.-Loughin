---
title: "Chp2 Q5"
output: rmarkdown::github_document
editor_options: 
  chunk_output_type: console
---
a). The estimated logistic regression model is: logit(pi.hat) = 5.085 - 0.1156Temp
```{r}
challenger <- read.table(file = "challenger.csv", 
                          header = TRUE, sep = ",")

challenger.fit <- glm(formula = O.ring/Number ~ Temp, 
                      family = binomial, 
                      data = challenger) 
#there is nothing wrong with this warning message, glm() is just picky when it comes to specifying binomial models

summary(challenger.fit)
```

b).
```{r}
linear.pred <- challenger.fit$coefficients[1] + challenger.fit$coefficients[2] * 31:81
pi.hat <- as.numeric(exp(linear.pred)/(1 + exp(linear.pred)))

plot(x = c(31:81), y = pi.hat, xlab = 'Tempture', 
     ylab = "Estimated probability", main = "pi vs. Temp")
```

```{r}
plot(x = c(31:81), y = linear.pred, xlab = 'Tempture', 
     ylab = "Expected number of failures", main = "Expected number of failures vs. Temp")
```

c). Bands are much wider for lower temperatures than for higher temperatures, because the calculation for Wald confidence interval for pi involves e to the power of "x". the value of "x" on the lower bands tend to be extreme, which makes Wald confidence interval to be wide.
```{r}
predict.data <- data.frame(Temp = 31:81) #create a data frame contains desired temperatures. 

linear.pred2 <- predict(object = challenger.fit,
                       newdata = predict.data,
                       type = "link",
                       se = TRUE)

pi.hat <- exp(linear.pred2$fit) / (1 + exp(linear.pred2$fit))

CI.lin.pred.upper <- linear.pred2$fit + 1.96 * linear.pred2$se
CI.pi.upper <- exp(CI.lin.pred.upper) / (1+exp(CI.lin.pred.upper))

CI.lin.pred.lower <- linear.pred2$fit - 1.96 * linear.pred2$se
CI.pi.lower <- exp(CI.lin.pred.lower) / (1+exp(CI.lin.pred.lower))

x <- data.frame(predict.data, pi.hat, 
           lower = CI.pi.lower, 
           upper = CI.pi.upper)

plot(x = c(31:81), y = pi.hat, xlab = 'Tempture', 
     ylab = "Estimated probability", main = "pi vs. Temp", ylim = c(0,1),
     type = "l", col = c("red"))
lines(x$Temp, x$upper, col = c("blue"))
lines(x$Temp, x$lower, col = c("blue"))
legend(60,1,legend=c("Logistic regression model",
                     "95% Wald C.I. bands"), 
       col=c("red", "blue"), 
       lty=1:1, cex=0.8)
```

d). At temperature 31, it has 0.8178 failure rate and confidence intervals are (0.0019, 0.9999). The assumptions needed are: assumption of independence and assumes that the model follows logistic regression. 
```{r}
x[1,]
```

e).
```{r}
beta0 <- 5.085
beta1 <- -0.1156

  # Explanatory variable values and corresponding pi's
  set.seed(321)
  x1<-runif(n = 966, min = 31, max = 72)
  pi<-exp(beta0 + beta1*x1) / (1 + exp(beta0 + beta1*x1))

  # Set seed number to reproduce results and simulate responses
  set.seed(123)
  y<-rbinom(n = length(x1), size = 966, prob = pi)/966
  
  # Estimate model
  mod.fit<-glm(formula = y ~ x1, family = binomial(link = logit))  # no data argument needed
  mod.fit$coefficients


predict.data <- data.frame(x1 = c(31,72)) #create a data frame contains desired temperatures. 

linear.pred2 <- predict(object = mod.fit,
                       newdata = predict.data,
                       type = "link",
                       se = TRUE)

pi.hat <- exp(linear.pred2$fit) / (1 + exp(linear.pred2$fit))

CI.lin.pred.upper <- linear.pred2$fit + 1.96 * linear.pred2$se
CI.pi.upper <- exp(CI.lin.pred.upper) / (1+exp(CI.lin.pred.upper))

CI.lin.pred.lower <- linear.pred2$fit - 1.96 * linear.pred2$se
CI.pi.lower <- exp(CI.lin.pred.lower) / (1+exp(CI.lin.pred.lower))

data.frame(predict.data, pi.hat, 
           lower = CI.pi.lower, 
           upper = CI.pi.upper)
```

f). A quadratic term is not needed in the model for the temperature. Notice that the simulated data are well fitted into the logistic regression model
```{r}
summary(mod.fit)
```

